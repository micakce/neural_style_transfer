{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Style Transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micakce/nst_Arting/blob/master/Neural_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI5BvwTy_non",
        "colab_type": "text"
      },
      "source": [
        "# Neural Style Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGx9rPDtCPGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Download necessary files to get the project working\"\"\"\n",
        "\n",
        "# content_images: here we store the images we are going to be working on\n",
        "# output: here where we store the processed images\n",
        "!mkdir content_images output\n",
        "\n",
        "# download respository with userful files, nst_utils and some style images\n",
        "!git clone https://github.com/micakce/nst_Arting.git\n",
        "\n",
        "# download the model we are going to be working with\n",
        "!wget http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82rd-Ko59cAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('nst_Arting/')\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "from nst_utils import *\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import imageio\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Feq_XvsPAl3j",
        "colab_type": "text"
      },
      "source": [
        "### Main functions definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyRSYPgv6WBs",
        "colab_type": "text"
      },
      "source": [
        "#### compute_content_cost\n",
        "\n",
        "difference between the content image and the generated image: \n",
        "$$J_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2\\tag{1} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-joYOzlGcm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_content_cost(a_C, a_G):\n",
        "    \"\"\"\n",
        "    Computes the content cost\n",
        "    \n",
        "    Arguments:\n",
        "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_content -- scalar that you compute using equation 1 above.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    # Reshape a_C and a_G (≈2 lines)\n",
        "    a_C_unrolled = tf.reshape(a_C, [n_H*n_W, n_C])\n",
        "    a_G_unrolled = tf.reshape(a_G, [n_H*n_W, n_C])\n",
        "    \n",
        "    # compute the cost with tensorflow (≈1 line)\n",
        "    J_content = (1/(4*n_H*n_W*n_C))*tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled)))\n",
        "    \n",
        "    return J_content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEmDW3RQ6d1O",
        "colab_type": "text"
      },
      "source": [
        "#### gram_matrix(A): \n",
        "Calculates de correlation between filters:\n",
        "$G_A = AA^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uew7Xb_4HRtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(A):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    A -- matrix of shape (n_C, n_H*n_W)\n",
        "    \n",
        "    Returns:\n",
        "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    GA = tf.matmul(A, A, transpose_b=True)\n",
        "    \n",
        "    return GA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNhbmEkg6mX0",
        "colab_type": "text"
      },
      "source": [
        "#### compute_layer_style_cost(a_S, a_G)\n",
        "Calculate the difference between the filter correlation (Gram Matrices) of the style image and the generated image:\n",
        "$$J_{style}^{[l]}(S,G) = \\frac{1}{4 \\times {n_C}^2 \\times (n_H \\times n_W)^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(G^{(S)}_{ij} - G^{(G)}_{ij})^2\\tag{2} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C29ZZ4PfLf_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_layer_style_cost(a_S, a_G, a_S_2 = 0):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
        "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
        "    \n",
        "    Returns: \n",
        "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve dimensions from a_G (≈1 line)\n",
        "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
        "    \n",
        "    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)\n",
        "    a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C]))\n",
        "        \n",
        "    if a_S_2 != 0:\n",
        "        a_S_2 = tf.transpose(tf.reshape(a_S_2, [n_H*n_W, n_C]))\n",
        "        a_S = tf.add(a_S, a_S_2)\n",
        "            \n",
        "    a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C]))\n",
        "\n",
        "    # Computing gram_matrices for both images S and G (≈2 lines)\n",
        "    GS = gram_matrix(a_S)\n",
        "    GG = gram_matrix(a_G)\n",
        "\n",
        "    # Computing the loss (≈1 line)\n",
        "    J_style_layer = (1/(4*(n_C**2)*(n_H*n_W)**2)) * tf.reduce_sum(tf.square(tf.subtract(GS, GG)))\n",
        "    \n",
        "    return J_style_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETMGJjNP62_R",
        "colab_type": "text"
      },
      "source": [
        "#### compute_style_cost(model, STYLE_LAYERS)\n",
        "Computes the cost for several layers of the model so style transfer is more efective:\n",
        "$$J_{style}(S,G) = \\sum_{l} \\lambda^{[l]} J^{[l]}_{style}(S,G)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qnsDZMfL9Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_style_cost(model, STYLE_LAYERS):\n",
        "    \"\"\"\n",
        "    Computes the overall style cost from several chosen layers\n",
        "    \n",
        "    Arguments:\n",
        "    model -- our tensorflow model\n",
        "    STYLE_LAYERS -- A python list containing:\n",
        "                        - the names of the layers we would like to extract style from\n",
        "                        - a coefficient for each of them\n",
        "    \n",
        "    Returns: \n",
        "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
        "    \"\"\"\n",
        "    \n",
        "    # initialize the overall style cost\n",
        "    J_style = 0\n",
        "\n",
        "    for layer_name, coeff in STYLE_LAYERS:\n",
        "\n",
        "        # Select the output tensor of the currently selected layer\n",
        "        out = model[layer_name]\n",
        "\n",
        "        # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out\n",
        "        a_S = sess.run(out)\n",
        "\n",
        "        # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] \n",
        "        # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "        # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "        a_G = out\n",
        "        \n",
        "        # Compute style_cost for the current layer\n",
        "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
        "\n",
        "        # Add coeff * J_style_layer of this layer to overall style cost\n",
        "        J_style += coeff * J_style_layer\n",
        "\n",
        "    return J_style"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY1Vp2LM7C6E",
        "colab_type": "text"
      },
      "source": [
        "#### total_cost(J_content, J_style, alpha=10, beta=40)\n",
        "Computes the total cost in order to minimize both the style and the content cost: \n",
        "$$J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcEkmhqDL-M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
        "    \"\"\"\n",
        "    Computes the total cost function\n",
        "    \n",
        "    Arguments:\n",
        "    J_content -- content cost coded above\n",
        "    J_style -- style cost coded above\n",
        "    alpha -- hyperparameter weighting the importance of the content cost\n",
        "    beta -- hyperparameter weighting the importance of the style cost\n",
        "    \n",
        "    Returns:\n",
        "    J -- total cost as defined by the formula above.\n",
        "    \"\"\"\n",
        "    \n",
        "    J = alpha*J_content + beta*J_style\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoIewD3WC82W",
        "colab_type": "text"
      },
      "source": [
        "#### readImageFromURL\n",
        "\n",
        "Makes it easy to work with files that are online, you can get the image right from the URL without having to save it on the server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7hdlUqzfJf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readImageFromURL(url, width=0, height=0, content=0):\n",
        "  \"\"\"\n",
        "  Read images right from URLs\n",
        "  \n",
        "  Arguments:\n",
        "  url -- URL of the image\n",
        "  width -- Width of the output image\n",
        "  height -- Height of the output image\n",
        "  \"\"\"\n",
        "  image = np.array(Image.open(urllib.request.urlopen(url)))\n",
        "\n",
        "  # if both set, use custom size, if not use content image size\n",
        "  if width and height:\n",
        "    CONFIG.IMAGE_WIDTH = width\n",
        "    CONFIG.IMAGE_HEIGHT = height\n",
        "  elif content:\n",
        "    CONFIG.IMAGE_WIDTH = image.shape[1]\n",
        "    CONFIG.IMAGE_HEIGHT = image.shape[0]\n",
        "\n",
        "  image = np.array(Image.fromarray(image).resize((CONFIG.IMAGE_WIDTH,CONFIG.IMAGE_HEIGHT)))\n",
        "  imshow(image)\n",
        "  image = reshape_and_normalize_image(image)\n",
        "  \n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJOd8PnO7SOY",
        "colab_type": "text"
      },
      "source": [
        "## Setting parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqb-AJVdTh7-",
        "colab_type": "text"
      },
      "source": [
        "### Uploading images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ3-ztrTX7sg",
        "colab_type": "text"
      },
      "source": [
        "#### Uploading pictures from local storage\n",
        "\n",
        "Here you get prompted to upload an image and, it will be processed and displayed. Make sure to upload always the content image first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gspzNrrMFF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Uploading content_image\"\"\"\n",
        "content_image = files.upload()\n",
        "content_image = imageio.imread('/content/'+list(content_image.keys())[0])\n",
        "imshow(content_image)\n",
        "CONFIG.IMAGE_WIDTH = content_image.shape[1]\n",
        "CONFIG.IMAGE_HEIGHT = content_image.shape[0]\n",
        "content_image = np.array(Image.fromarray(content_image).resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT)))\n",
        "content_image = reshape_and_normalize_image(content_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Gk0t3fIZu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Uploading style_image\"\"\"\n",
        "style_image = files.upload()\n",
        "style_image = imageio.imread('/content/'+list(style_image.keys())[0])\n",
        "style_image = np.array(Image.fromarray(style_image).resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT)))\n",
        "imshow(style_image)\n",
        "style_image = reshape_and_normalize_image(style_image)\n",
        "style_images = [(style_image, 1)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo3v9HSmY2_6",
        "colab_type": "text"
      },
      "source": [
        "#### Uploading from remote server\n",
        "\n",
        "You can also use URLs to upload images from the internet. Again, make sure to upload the content image first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Eriwr3ATFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Use this to work with images on internet\"\"\"\n",
        "\n",
        "content_URL = 'https://lh3.googleusercontent.com/sbEeESnZ-bRgheIZXG5YlBvu0NDPJffUOxnS7wtu3-TjA7DVGO-eBy_8-AFEqIpwwfr8Gs9Fj3848XgYnpn9cTheTPj09J85Yl5jDYAE8lO0-XKfmobHwlnkXXYR64eh6EZgYaWt03mAnXzY7dU7jlOwsCeH9a-Hu5uLeycqbTBi8s1tH02cb4K9GTN1AYSoV-2C0CU0jSgSrDYSYN65FjDcXIyQ1CyGdfR6toOFiJLP-FXNxrbdpDeQBHyrzUVhRe8vHHxPIOJ8n6JqEyZx-qRoAO9dsJuHTWi43iLr_EG2SUx-vHYE9HtczXdBmuyt8B9lRjdEBdru_25gldbvuGwvD0ihRu-wvtGfmQtw5hy0TdpL5r-Aq_fP-uouxU3nc8a3010ItT50OEao8zwWGa5pUHaZ8mLiqQecvidvhxC7Mvq0gp804d85qgyqjMH_uSHIcvjSX0ZX5PGSSl8yWeeWQ-DZIwqVkFMjUrCZnxI5-Gywf5G-Yy6Ybt-zT1PHaYq5GcpQw-Makt2edfGODwWHGMZuDxLpfa0lu8RhVKTKCTEMLz-nxYs-1VQBiQWnH5_XQR3_5MuYHjwKzFnriaizSzMLX1OuBtZOnJsgxgOe87XWMy2YRaBoycSFS80g9gmGBiBU5NI20m6cg0dvZupSw_upSPAp=w784-h588-no'\n",
        "style_URL = 'https://afremov.com/images/product/MELODY-OF-THE-NIGHT.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeLdslnNLsA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load content image\n",
        "content_image = readImageFromURL(content_URL, content=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WrL-4jLqCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load style image\n",
        "style_image = readImageFromURL(style_URL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1yuZlLZMvF",
        "colab_type": "text"
      },
      "source": [
        "#### Using predefined styles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_YbdjM3I2g_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Read and show some style images stored in the repo\"\"\"\n",
        "style_images_list = [\n",
        "    \"starry_night.jpg\",\n",
        "    \"starry_night_comic.jpg\",\n",
        "    \"style_3.jpg\",\n",
        "    \"the_scream.jpg\",\n",
        "    \"dream.jpg\",\n",
        "    \"brussel_street.jpg\",\n",
        "    \"dripping_colors.jpg\",\n",
        "    \"fox.jpg\",    \n",
        "    \"fox2.jpg\",\n",
        "    \"style_4.jpg\",\n",
        "    \"tree_house.png\",\n",
        "]\n",
        "\n",
        "l = len(style_images_list)\n",
        "y = 4\n",
        "x = math.ceil(l / y)\n",
        "\n",
        "f, axes = plt.subplots(x,y, figsize=(CONFIG.IMAGE_WIDTH/95,CONFIG.IMAGE_HEIGHT/95))\n",
        "\n",
        "style_images_dict = {}\n",
        "\n",
        "for i, style in enumerate(style_images_list):\n",
        "  style_im = imageio.imread(\"/content/nst_Arting/style_images/\"+style)\n",
        "  style_im = np.array(Image.fromarray(style_im).resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT)))\n",
        "#   Image.fromarray(style_im).save(style)\n",
        "#   files.download('/content/' + style)\n",
        "  ax = math.floor(i/y)\n",
        "  ay = (i % y)\n",
        "  axes[ax,ay].imshow(style_im)\n",
        "  axes[ax,ay].set_xlabel(style)\n",
        "  style_images_dict[style] = reshape_and_normalize_image(style_im)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llbMhjk6Qd_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Uncomment corresponding line to use the desired style, uncomment more than one if you want\n",
        "to mix styles, also can set the weight for each style\"\"\"\n",
        "\n",
        "# style_images = []\n",
        "# style_images.append((style_images_dict[\"starry_night.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"starry_night_comic.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"style_3.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"the_scream.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"dream.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"brussel_street.jpg\"], 1))\n",
        "style_images.append((style_images_dict[\"dripping_colors.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"fox.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"fox2.jpg\"], 1))\n",
        "# style_images.append((style_images_dict[\"style_4.jpg], 1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SBlhMRkMhTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Set what layer of the model to use for the style transfer, each layer captures different features\n",
        "of the image, can also set the weight for each layer\"\"\"\n",
        "\n",
        "STYLE_LAYERS = [\n",
        "    ('conv1_1', .9), \n",
        "    ('conv1_2', .5),\n",
        "    ('conv2_1', .9),\n",
        "    ('conv2_2', .9),\n",
        "    ('conv3_1', .9),\n",
        "#    ('conv3_2', .9),\n",
        "#    ('conv4_1', .9),\n",
        "#    ('conv4_2', .9),\n",
        "#    ('conv4_3', .9),\n",
        "#    ('conv4_4', .9),\n",
        "#    ('conv5_1', .9),\n",
        "#    ('conv5_2', .5),\n",
        "#    ('conv5_3', .5),\n",
        "#    ('conv5_4', .5)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb2471liMblg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate noise image with resemblance to the the content image for faster convergence\n",
        "generated_image = generate_noise_image(content_image)\n",
        "imshow(generated_image[0])\n",
        "print(content_image.shape, style_images[0][0].shape, generated_image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70GJR2JYZXmE",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhO7yPz_MCbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset the graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Start interactive session\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "#devices = sess.list_devices()\n",
        "#for d in devices:\n",
        "#  print(d.name)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYkxzvatMeNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_vgg_model(\"imagenet-vgg-verydeep-19.mat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5rAB5SiNVW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign the content image to be the input of the VGG model.  \n",
        "sess.run(model['input'].assign(content_image))\n",
        "\n",
        "# Select the output tensor of layer conv4_2\n",
        "out = model['conv4_2']\n",
        "\n",
        "# Set a_C to be the hidden layer activation from the layer we have selected\n",
        "a_C = sess.run(out)\n",
        "\n",
        "# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] \n",
        "# and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "a_G = out\n",
        "\n",
        "# Compute the content cost\n",
        "J_content = compute_content_cost(a_C, a_G)\n",
        "\n",
        "\n",
        "J_S = 0\n",
        "for image in style_images:\n",
        "  sess.run(model['input'].assign(image[0]))\n",
        "  J_style = compute_style_cost(model, STYLE_LAYERS)\n",
        "  J_S += image[1]*J_style\n",
        "\n",
        "# Total cost\n",
        "J = total_cost(J_content, J_S)\n",
        "\n",
        "# define optimizer (1 line)\n",
        "optimizer = tf.train.AdamOptimizer(2.0)\n",
        "\n",
        "# define train_step (1 line)\n",
        "train_step = optimizer.minimize(J)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLxvLwjPNeK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_nn(sess, input_image, num_iterations = 500):\n",
        "    \n",
        "    # Initialize global variables (you need to run the session on the initializer)\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
        "    generated_image = sess.run(model['input'].assign(input_image))\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "    \n",
        "        # Run the session on the train_step to minimize the total cost\n",
        "        sess.run(train_step)\n",
        "        \n",
        "        # Compute the generated image by running the session on the current model['input']\n",
        "        generated_image = sess.run(model['input'])\n",
        "\n",
        "        # Print every 20 iteration.\n",
        "        if i%50 == 0:\n",
        "            Jt, Jc, Js = sess.run([J, J_content, J_S])\n",
        "            print(\"Iteration \" + str(i) + \" :\")\n",
        "            print(\"total cost = \" + str(Jt))\n",
        "            print(\"content cost = \" + str(Jc))\n",
        "            print(\"style cost = \" + str(Js))\n",
        "            \n",
        "            # save current generated image in the \"/output\" directory\n",
        "            save_image(\"output/\" + str(i) + \".png\", generated_image)\n",
        "    \n",
        "    # save last generated image\n",
        "    save_image('output/generated_image.jpg', generated_image)\n",
        "    \n",
        "    return generated_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwJrn9RlNf-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_nn(sess, generated_image, num_iterations=2500)\n",
        "generated_im = imageio.imread('output/generated_image.jpg')\n",
        "imshow(generated_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKtPFuoIHEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('output/generated_image.jpg')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vcAf5Ywaiur",
        "colab_type": "text"
      },
      "source": [
        "### Miscelaneos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY-lJO1DRyzo",
        "colab_type": "text"
      },
      "source": [
        "#### Run all styles\n",
        "\n",
        "This code applies the transfer style one model layer at the time, showing how each layer affects the output image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jEhZsx8Jn0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_per_layer(sess, input_image, num_iterations = 1500):\n",
        "    \n",
        "    # Initialize global variables (you need to run the session on the initializer)\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
        "    generated_image = sess.run(model['input'].assign(input_image))\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "    \n",
        "        # Run the session on the train_step to minimize the total cost\n",
        "        sess.run(train_step)\n",
        "        \n",
        "        # Compute the generated image by running the session on the current model['input']\n",
        "        generated_image = sess.run(model['input'])\n",
        "\n",
        "    # save last generated image\n",
        "    save_image('output/generated_image_'+ style[0] +'.jpg', generated_image)\n",
        "    \n",
        "    return generated_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Css783Ax4oV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STYLE_LAYERS = [\n",
        "    ('conv1_1', 1), ('conv1_2', 1),\n",
        "    ('conv2_1', 1), ('conv2_2', 1),\n",
        "    ('conv3_1', 1), ('conv3_2', 1), \n",
        "    ('conv4_1', 1), ('conv4_2', 1), ('conv4_3', 1), ('conv4_4', 1), \n",
        "    ('conv5_1', 1), ('conv5_2', 1), ('conv5_3', 1), ('conv5_4', 1) \n",
        "]\n",
        "\n",
        "for style in STYLE_LAYERS:\n",
        "    # Assign the content image to be the input of the VGG model.\n",
        "    sess.run(model['input'].assign(content_image))\n",
        "\n",
        "    # Select the output tensor of layer conv4_2\n",
        "    out = model['conv4_2']\n",
        "\n",
        "    # Set a_C to be the hidden layer activation from the layer we have selected\n",
        "    a_C = sess.run(out)\n",
        "\n",
        "    # Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2']\n",
        "    # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "    # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "    a_G = out\n",
        "\n",
        "    # Compute the content cost\n",
        "    J_content = compute_content_cost(a_C, a_G)\n",
        "\n",
        "\n",
        "    J_S = 0\n",
        "    for image in style_images:\n",
        "        sess.run(model['input'].assign(image[0]))\n",
        "        J_style = compute_style_cost(model, [style])\n",
        "        J_S += image[1]*J_style\n",
        "\n",
        "    # Total cost\n",
        "    J = total_cost(J_content, J_S)\n",
        "\n",
        "    # define optimizer (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(2.0)\n",
        "\n",
        "    # define train_step (1 line)\n",
        "    train_step = optimizer.minimize(J)\n",
        "    \n",
        "    generated_image = generate_noise_image(content_image)\n",
        "    \n",
        "\n",
        "    model_per_layer(sess, generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDjES3vqYSg7",
        "colab_type": "text"
      },
      "source": [
        "#### Run style layers combinations\n",
        "\n",
        "Here you can set up different sets of layers combinations to let it running and get and compare the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyviEVnUYATV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_per_layer(sess, input_image, num_iterations = 1500):\n",
        "    \n",
        "    # Initialize global variables (you need to run the session on the initializer)\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Run the noisy input image (initial generated image) through the model. Use assign().\n",
        "    generated_image = sess.run(model['input'].assign(input_image))\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "    \n",
        "        # Run the session on the train_step to minimize the total cost\n",
        "        sess.run(train_step)\n",
        "        \n",
        "        # Compute the generated image by running the session on the current model['input']\n",
        "        generated_image = sess.run(model['input'])\n",
        "\n",
        "    # save last generated image\n",
        "    save_image('output/generated_image_'+ name +'.jpg', generated_image)\n",
        "    \n",
        "    return generated_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86mDMoaG6RPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STYLE_LAYERS = [ \n",
        "#    [('conv1_1', 1), ('conv1_2', 1), 'layer_1'], \n",
        "#    [('conv2_1', 1), ('conv2_2', 1), 'layer_2(2)'], \n",
        "#    [('conv3_1', 1), ('conv3_2', 1), 'layer_3'], \n",
        "#    [('conv4_1', 1), ('conv4_2', 1), ('conv4_3', 1), ('conv4_4', 1), 'layer_4'], \n",
        "#    [('conv1_1', 1), ('conv1_2', 1), ('conv2_1', 1), ('conv2_2', 1), ' layer_1_2(2)'],\n",
        "#    [('conv1_1', 1), ('conv1_2', 1), ('conv3_1', 1), ('conv3_2', 1), ' layer_1_3(2)'],\n",
        "#    [('conv2_1', 1), ('conv2_2', 1), ('conv3_1', 1), ('conv3_2', 1), ' layer_2_3'],\n",
        "#    [('conv3_1', 1), ('conv3_2', 1), ('conv4_1', 1), ('conv4_2', 1), ' layer_3_4.1_4.2'],\n",
        "#    [('conv1_1', 1), ('conv1_2', 1), ('conv2_1', 1), ('conv2_2', 1), ('conv3_1', 1), ('conv3_2', 1), ('conv4_1', 1), ('conv4_2', 1), ' layer_1_2_3_4.1.2'],\n",
        "#    [('conv1_1', 1), ('conv1_2', 1), ('conv2_1', 1), ('conv2_2', 1), ('conv3_1', 1), ('conv3_2', 1), ' layer_1_2_3'],\n",
        "#    [('conv1_1', 1), ('conv2_1', 1), ('conv3_1', 1), ' layer_1.1_2.1_3.1'],\n",
        "#    [('conv1_2', 1), ('conv2_2', 1), ('conv3_2', 1), ' layer_1.2_2.2_3.2'],\n",
        "    [('conv3_1', 1), ('conv3_2', 1), ' layer_3(2)'],\n",
        "]\n",
        "\n",
        "for style in STYLE_LAYERS:\n",
        "\n",
        "    name = style.pop()\n",
        "    # Assign the content image to be the input of the VGG model.\n",
        "    sess.run(model['input'].assign(content_image))\n",
        "\n",
        "    # Select the output tensor of layer conv4_2\n",
        "    out = model['conv4_2']\n",
        "\n",
        "    # Set a_C to be the hidden layer activation from the layer we have selected\n",
        "    a_C = sess.run(out)\n",
        "\n",
        "    # Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2']\n",
        "    # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that\n",
        "    # when we run the session, this will be the activations drawn from the appropriate layer, with G as input.\n",
        "    a_G = out\n",
        "\n",
        "    # Compute the content cost\n",
        "    J_content = compute_content_cost(a_C, a_G)\n",
        "\n",
        "\n",
        "    J_S = 0\n",
        "    for image in style_images:\n",
        "        sess.run(model['input'].assign(image[0]))\n",
        "        J_style = compute_style_cost(model, style)\n",
        "        J_S += image[1]*J_style\n",
        "\n",
        "    # Total cost\n",
        "    J = total_cost(J_content, J_S)\n",
        "\n",
        "    # define optimizer (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(2.0)\n",
        "\n",
        "    # define train_step (1 line)\n",
        "    train_step = optimizer.minimize(J)\n",
        "    \n",
        "    generated_image = generate_noise_image(content_image)\n",
        "    \n",
        "\n",
        "    model_per_layer(sess, generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0CA6AfHRuxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Download each of the per layer generated images \"\"\"\n",
        "\n",
        "files.download('output/generated_image_inferno_conv1_1.jpg')\n",
        "files.download('output/generated_image_inferno_conv1_2.jpg')\n",
        "files.download('output/generated_image_inferno_conv2_1.jpg')\n",
        "files.download('output/generated_image_inferno_conv2_2.jpg')\n",
        "files.download('output/generated_image_inferno_conv3_1.jpg')\n",
        "files.download('output/generated_image_inferno_conv3_2.jpg')\n",
        "files.download('output/generated_image_inferno_conv4_1.jpg')\n",
        "files.download('output/generated_image_inferno_conv4_2.jpg')\n",
        "files.download('output/generated_image_inferno_conv4_3.jpg')\n",
        "files.download('output/generated_image_inferno_conv4_4.jpg')\n",
        "files.download('output/generated_image_inferno_conv5_1.jpg')\n",
        "files.download('output/generated_image_inferno_conv5_2.jpg')\n",
        "files.download('output/generated_image_inferno_conv5_3.jpg')\n",
        "files.download('output/generated_image_inferno_conv5_4.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO58NH2TugCY",
        "colab_type": "text"
      },
      "source": [
        "#### visualize CNN outputs\n",
        "\n",
        "This code show you what each filter of each layer in the model is looking at when processing the (style) images.\n",
        "\n",
        "**\\#TODO**: Get the nodes/layers that get activated the most when processing the images. With this we get to know what nodes/layers are looking at exactly (patterns/features in the image) and get a better idea of what layers would do better with different kinds of style images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGUStCz0e53B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(model['input'].assign(style_image_6))\n",
        "layer_outputs = ['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2', 'conv3_1', \n",
        "                 'conv3_2', 'conv4_1', 'conv4_2', 'conv4_3', 'conv4_4', \n",
        "                 'conv5_1', 'conv5_2', 'conv5_3', 'conv5_4']\n",
        "x = len(layer_outputs)\n",
        "y = 30\n",
        "f, axarr = plt.subplots(x,y, figsize=(120,42))\n",
        "#f.figure(figsize=(10,10))\n",
        "for i,layer in enumerate(layer_outputs):\n",
        "  out = model[layer]\n",
        "  im = sess.run(out)\n",
        "  for j in range(0,y):\n",
        "    axarr[i,j].imshow(im[0,:,:,j])\n",
        "    axarr[i,j].grid(False)\n",
        "    axarr[i,j].set_ylabel(layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JsZVtrcSn6D",
        "colab_type": "text"
      },
      "source": [
        "#### GPU\n",
        "\n",
        "Verify that the GPU is working.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU6WqEsi_YTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oaIkeMLaib6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wurlitzer\n",
        "# Creates a graph.\n",
        "#a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "#b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "#c = tf.matmul(a, b)\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "#from wurlitzer import pipes\n",
        "\n",
        "with pipes() as (out, err):\n",
        "  with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "    print(sess.run(c))\n",
        "\n",
        "print (out.read())\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}